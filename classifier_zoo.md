## ğŸ“š Table of Contents (Classifiers Section)

- [ğŸ“š Table of Contents (Classifiers Section)](#-table-of-contents-classifiers-section)
  - [âš™ï¸ Training Algorithms](#ï¸-training-algorithms)
  - [ğŸ§  Model Architectures \& Pretraining](#-model-architectures--pretraining)
  - [ğŸ§ª Training scripts for different classifiers](#-training-scripts-for-different-classifiers)
  - [ğŸ¥ Training ResNet50 using ERM (`resnet_sup_in1k`) as classifier for NIH-CXR](#-training-resnet50-using-erm-resnet_sup_in1k-as-classifier-for-nih-cxr)
  - [ğŸ¥ Training EfficientNet-B5 (`EN-B5`) using ERM as classifier for RSNA-Mammo](#-training-efficientnet-b5-en-b5-using-erm-as-classifier-for-rsna-mammo)
  - [ğŸ¥ Training EfficientNet-B5 (`EN-B5`) as classifier for VinDr-Mammo](#-training-efficientnet-b5-en-b5-as-classifier-for-vindr-mammo)

### âš™ï¸ Training Algorithms

We support a wide range of algorithms for bias mitigation and robust training.  
[Click here to view the implementation](./src/codebase/SubpopBench-main/subpopbench/learning/algorithms.py).

- **ERM** â€” Empirical Risk Minimization ([Vapnik, 1998](https://www.wiley.com/en-fr/Statistical+Learning+Theory-p-9780471030034))
- **IRM** â€” Invariant Risk Minimization ([Arjovsky et al., 2019](https://arxiv.org/abs/1907.02893))
- **GroupDRO** â€” Group Distributionally Robust Optimization ([Sagawa et al., 2020](https://arxiv.org/abs/1911.08731))
- **CVaRDRO** â€” Conditional Value-at-Risk DRO ([Duchi & Namkoong, 2018](https://arxiv.org/abs/1810.08750))
- **Mixup** ([Zhang et al., 2018](https://arxiv.org/abs/1710.09412))
- **JTT** â€” Just Train Twice ([Liu et al., 2021](http://proceedings.mlr.press/v139/liu21f.html))
- **LfF** â€” Learning from Failure ([Nam et al., 2020](https://proceedings.neurips.cc/paper/2020/file/eddc3427c5d77843c2253f1e799fe933-Paper.pdf))
- **LISA** â€” Learning Invariant Selective Augmentation ([Yao et al., 2022](https://arxiv.org/abs/2201.00299))
- **DFR** â€” Deep Feature Reweighting ([Kirichenko et al., 2022](https://arxiv.org/abs/2204.02937))
- **MMD** â€” Maximum Mean Discrepancy ([Li et al., 2018](https://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Domain_Generalization_With_CVPR_2018_paper.pdf))
- **CORAL** â€” Deep Correlation Alignment ([Sun & Saenko, 2016](https://arxiv.org/abs/1607.01719))
- **ReSample** â€” Data Re-Sampling ([Japkowicz, 2000](https://site.uottawa.ca/~nat/Papers/ic-ai-2000.ps))
- **ReWeight** â€” Cost-Sensitive Re-Weighting ([Japkowicz, 2000](https://site.uottawa.ca/~nat/Papers/ic-ai-2000.ps))
- **SqrtReWeight** â€” Square-Root Reweighting ([Japkowicz, 2000](https://site.uottawa.ca/~nat/Papers/ic-ai-2000.ps))
- **Focal** â€” Focal Loss ([Lin et al., 2017](https://arxiv.org/abs/1708.02002))
- **CBLoss** â€” Class-Balanced Loss ([Cui et al., 2019](https://arxiv.org/abs/1901.05555))
- **LDAM** â€” Label-Distribution-Aware Margin Loss ([Cao et al., 2019](https://arxiv.org/abs/1906.07413))
- **BSoftmax** â€” Balanced Softmax ([Ren et al., 2020](https://arxiv.org/abs/2007.10740))
- **CRT** â€” Classifier Re-Training ([Kang et al., 2020](https://arxiv.org/abs/1910.09217))

---

### ğŸ§  Model Architectures & Pretraining

[Supported image model architectures are implemented here](./src/codebase/SubpopBench-main/subpopbench/models/networks.py).

**ResNet-50 Variants**

- `resnet_sup_in1k` â€” Supervised on ImageNet-1K
- `resnet_sup_in21k` â€” Supervised on ImageNet-21K ([Ridnik et al., 2021](https://arxiv.org/pdf/2104.10972v4.pdf))
- `resnet_simclr_in1k` â€” SimCLR ([Chen et al., 2020](https://arxiv.org/abs/2002.05709))
- `resnet_barlow_in1k` â€” Barlow Twins ([Zbontar et al., 2021](https://arxiv.org/abs/2103.03230))
- `resnet_dino_in1k` â€” DINO ([Caron et al., 2021](https://arxiv.org/abs/2104.14294))

**ViT-B Variants**

- `vit_sup_in1k` â€” Supervised on ImageNet-1K ([Steiner et al., 2021](https://arxiv.org/abs/2106.10270))
- `vit_sup_in21k` â€” Supervised on ImageNet-21K ([Steiner et al., 2021](https://arxiv.org/abs/2106.10270))
- `vit_clip_oai` â€” CLIP (OpenAI) ([Radford et al., 2021](https://arxiv.org/abs/2103.00020))
- `vit_clip_laion` â€” OpenCLIP on LAION-2B ([OpenCLIP](https://github.com/mlfoundations/open_clip))
- `vit_sup_swag` â€” Supervised on SWAG ([Singh et al., 2022](https://arxiv.org/abs/2201.08371))
- `vit_dino_in1k` â€” DINO ([Caron et al., 2021](https://arxiv.org/abs/2104.14294))

---

### ğŸ§ª Training scripts for different classifiers

Training scripts for different datasets are available in the repo:

- ğŸ“· [CelebA](./src/codebase/SubpopBench-main/scripts_bash_celebA.sh)
- ğŸ¶ [MetaShift](./src/codebase/SubpopBench-main/scripts_bash_metashift.sh)
- ğŸ« [NIH ChestX-ray using subpopshift](./src/codebase/SubpopBench-main/scripts_bash_nih.sh)
- ğŸ¦ [Waterbirds](./src/codebase/SubpopBench-main/scripts_bash_waterbirds.sh)

### ğŸ¥ Training ResNet50 using ERM (`resnet_sup_in1k`) as classifier for NIH-CXR

We train the ERM variant for NIH-CXR as follows:

```bash
python ./src/codebase/train_classifier_CXR.py --img-size 224 --arch ResNet50 --lr 1e-5
```

### ğŸ¥ Training EfficientNet-B5 (`EN-B5`) using ERM as classifier for RSNA-Mammo

We train the ERM variant for RSNA-Mammo as follows:

```bash
python ./src/codebase/train_classifier_Mammo.py \
  --data-dir 'Data/RSNA_Breast_Imaging/Dataset/' \
  --img-dir 'RSNA_Cancer_Detection/train_images_png' \
  --csv-file 'RSNA_Cancer_Detection/rsna_w_upmc_concepts_breast_clip.csv' --start-fold 0 --n_folds 1 \
  --dataset 'RSNA' --arch 'tf_efficientnet_b5_ns-detect' --epochs 9 --batch-size 6 --num-workers 0 \
  --print-freq 10000 --log-freq 500 --running-interactive 'n' \
  --lr 5.0e-5 --weighted-BCE 'y' --balanced-dataloader 'n' \
  --tensorboard-path="out/RSNA/fold0" \
  --checkpoints="out/RSNA/fold0" \
  --output_path="out/RSNA/fold0" \
  --label "cancer"
```

### ğŸ¥ Training EfficientNet-B5 (`EN-B5`) as classifier for VinDr-Mammo

We train the ERM variant for VinDr-Mammo as follows:

```bash
python ./src/codebase/train_classifier_Mammo.py \
  --data-dir 'Data/RSNA_Breast_Imaging/Dataset' \
  --img-dir 'External/Vindr/vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0/images_png' \
  --csv-file 'External/Vindr/vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0/vindr_detection_v1_folds_abnormal.csv' \
  --dataset 'ViNDr' --arch 'tf_efficientnet_b5_ns-detect' --epochs 20 --batch-size 8 --num-workers 0 \
  --print-freq 10000 --log-freq 500 --running-interactive 'n' \
  --lr 5.0e-5 --weighted-BCE 'y' --balanced-dataloader 'n'  --n_folds 1  --label "abnormal" \
  --tensorboard-path="out/ViNDr/fold0" \
  --checkpoints="out/ViNDr/fold0" \
  --output_path="out/ViNDr/fold0"

```
